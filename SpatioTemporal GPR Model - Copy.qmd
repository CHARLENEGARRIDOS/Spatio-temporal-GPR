---
title: "SpatioTemporal GPR"
author: "Garridos, Charlene P."
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 5
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Library

```{r, message=FALSE}
library(ggplot2)     
library(dplyr)
library(tidyr)
library(tidygeocoder)
library(lubridate)
library(reshape2)
library(sf)
library(tidyverse)
library(kernlab)
library(lubridate)
library(caret)
library(viridis)  
```

# Dataset

```{r}
data <- read.csv("C:/Users/User/Downloads/hungary_chickenpox5.csv", stringsAsFactors = FALSE)
head(data)
```

## Rename

```{r}
# Fix region names 
data <- data %>% rename(
  "BUDAPEST" = "BUDAPEST",
  "BARANYA" = "BARANYA",
  "BÁCS-KISKUN" = "BACS",
  "BÉKÉS" = "BEKES",
  "BORSOD-ABAÚJ-ZEMPLÉN" = "BORSOD",
  "CSONGRÁD" = "CSONGRAD",
  "FEJÉR" = "FEJER",
  "GYŐR-MOSON-SOPRON" = "GYOR",
  "HAJDÚ-BIHAR" = "HAJDU",
  "HEVES" = "HEVES",
  "JÁSZ-NAGYKUN-SZOLNOK" = "JASZ",
  "KOMÁROM-ESZTERGOM" = "KOMAROM",
  "NÓGRÁD" = "NOGRAD",
  "PEST" = "PEST", 
  "SOMOGY" = "SOMOGY",
  "SZABOLCS-SZATMÁR-BEREG" = "SZABOLCS",
  "TOLNA" = "TOLNA",
  "VAS" = "VAS",
  "VESZPRÉM" = "VESZPREM",
  "ZALA" = "ZALA"
)
```

## Date

```{r}
# Convert Date column to Date format
data$Date <- parse_date_time(data$Date, orders = c("d/m/Y", "d/m/y", "m/d/Y", "m/d/y"))
data$Date <- as.Date(data$Date)

# Convert Date to numeric (days since first date)
data$Date <- as.numeric(data$Date - min(data$Date))

# Sort dataset by Date
data <- data %>% arrange(Date)

# Convert Data to Long Format
data_long <- data %>%
  pivot_longer(-Date, names_to = "Region", values_to = "Value")
data_long
```

## Location

```{r}
# Geocode Hungarian Regions
regions <- data.frame(Region = unique(data_long$Region))
regions <- regions %>% geocode(address = Region, method = "osm")

# Convert lat/long to Cartesian coordinates (EPSG:23700)
regions_sf <- st_as_sf(regions, coords = c("long", "lat"), crs = 4326)
regions_sf <- st_transform(regions_sf, crs = 23700)
regions_coords <- st_coordinates(regions_sf)

# Append coordinates to regions
data_long <- data_long %>%
  left_join(mutate(regions, X = as.numeric(regions_coords[,1]), 
                   Y = as.numeric(regions_coords[,2])), by = "Region")
data_long
```

# Split

```{r}
set.seed(123)

# Extract unique weeks (dates)
unique_weeks <- unique(data_long$Date)

# Select 20% of weeks for testing
test_weeks <- sample(unique_weeks, size = round(length(unique_weeks) * 0.2))

# Split the data
train_data <- data_long[!data_long$Date %in% test_weeks, ]
test_data <- data_long[data_long$Date %in% test_weeks, ]

# Print dataset sizes
cat("Train Data:", nrow(train_data), "rows\n")
cat("Test Data:", nrow(test_data), "rows\n")

# Check how many regions per test week
test_summary <- table(test_data$Date)
print(test_summary)

```

```{r}
str(train_data)
str(test_data)
```

# Modeling: Single Kernel

```{r}
train_x <- scale(train_data[, c("Date", "X", "Y")])
test_x <- scale(test_data[, c("Date", "X", "Y")])
```

### Selected Kernels

```{r}
# Define selected kernels
selected_kernels <- c("rbfdot", "laplacedot", "besseldot")
models <- list()
optimized_params <- list()
metrics <- data.frame(Kernel = character(), RMSE = numeric(), R2 = numeric(), stringsAsFactors = FALSE)
```

### Evaluation Metric Function

```{r}
# Function to compute RMSE
rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

# Function to compute R-squared
r_squared <- function(actual, predicted) {
  1 - (sum((actual - predicted)^2) / sum((actual - mean(actual))^2))
}
```

```{r}
# Objective function for hyperparameter tuning (minimize RMSE)
rmse_objective <- function(params, train_x, train_y, kernel) {
  kpar_list <- list()
  
  if (kernel %in% c("rbfdot", "laplacedot")) {
    kpar_list$sigma <- params[1]
  } else if (kernel == "besseldot") {
    kpar_list$sigma <- params[1]
    kpar_list$order <- round(params[2])
    kpar_list$degree <- round(params[3])
  } 
  
  model <- tryCatch(
    gausspr(x = train_x, y = train_y, kernel = kernel, kpar = kpar_list),
    error = function(e) return(Inf)
  )
  
  preds <- tryCatch(
    predict(model, train_x),
    error = function(e) return(rep(Inf, length(train_y)))
  )
  
  return(sqrt(mean((preds - train_y)^2)))
}
```

### Optimized Hyperparameters

```{r}
# Training loop with optimization
for (kern in selected_kernels) {
  cat("\nOptimizing hyperparameters for kernel:", kern, "\n")
  
  if (kern %in% c("rbfdot", "laplacedot")) {
    init_vals <- c(1)
    lower_bounds <- c(1e-5)
    upper_bounds <- c(50)
  } else if (kern == "besseldot") {
    init_vals <- c(1, 1, 1)
    lower_bounds <- c(1e-5, 1, 1)
    upper_bounds <- c(50, 10, 10)
  } else {
    init_vals <- NULL
  }
  
  if (!is.null(init_vals)) {
    optim_result <- optim(
      par = init_vals,
      fn = function(par) rmse_objective(
        par = par,
        train_x = as.matrix(train_data[, c("Date", "X", "Y")]),
        train_y = train_data$Value,
        kernel = kern
      ),
      method = "L-BFGS-B",
      lower = lower_bounds,
      upper = upper_bounds,
      control = list(maxit = 5000)
    )
    opt_params <- optim_result$par
    optimized_params[[kern]] <- opt_params
  } else {
    opt_params <- NULL
  }
  
  if (kern == "besseldot") {
    cat("Optimized parameters for", kern, ":", opt_params[1], round(opt_params[2]), round(opt_params[3]), "\n")
  } else {
    cat("Optimized parameters for", kern, ":", opt_params[1], "\n")
  }

  kpar_list <- list()
  if (kern %in% c("rbfdot", "laplacedot")) {
    kpar_list$sigma <- opt_params[1]
  } else if (kern == "besseldot") {
    kpar_list$sigma <- opt_params[1]
    kpar_list$order <- round(opt_params[2])
    kpar_list$degree <- round(opt_params[3])
  } 
  
  models[[kern]] <- gausspr(
    x = as.matrix(train_data[, c("Date", "X", "Y")]),
    y = train_data$Value,
    kernel = kern,
    kpar = kpar_list
  )
}

cat("\n=== Trained Models ===\n")
print(models)
```

```{r}
optim_result$convergence
```

### Evaluation Metric Result

```{r}
# Evaluate models
for (kern in selected_kernels) {
  test_x <- as.matrix(test_data[, c("Date", "X", "Y")])
  test_y <- test_data$Value
  preds <- predict(models[[kern]], test_x)
  

  if (is.null(preds)) next
  
  rmse_val <- rmse(test_y, preds)
  r2_val <- r_squared(test_y, preds)
  
  metrics <- rbind(metrics, data.frame(Kernel = kern, RMSE = rmse_val, R2 = r2_val))
}

cat("\n=== Model Evaluation Metrics ===\n")
print(metrics)
```

```{r}

#output_dir <- "C:/Users/User/Downloads/SpatioTemporal GPR/Results"

# Create directory if it does not exist
#if (!dir.exists(output_dir)) {
#  dir.create(output_dir, recursive = TRUE)
#}

# Define the output file path
#log_filepath <- "C:/Users/User/Downloads/SpatioTemporal GPR/Results/training_log.txt"

# Start capturing console output
#sink(log_filepath, split = TRUE)

# Save optimization results
#csv_filepath <- "C:/Users/User/Downloads/SpatioTemporal GPR/Results/optimized_parameters.csv"
#write.csv(optimized_params, csv_filepath, row.names = FALSE)

#cat("\nSaved optimization results to:", csv_filepath, "\n")

# Save trained models
#rds_filepath <- "C:/Users/User/Downloads/SpatioTemporal GPR/Results/trained_models.rds"
#saveRDS(models, rds_filepath)

#cat("Saved trained models to:", rds_filepath, "\n")

#csv_filepath <- "C:/Users/User/Downloads/SpatioTemporal GPR/Results/metrics.csv"
#write.csv(metrics, csv_filepath, row.names = FALSE)

#cat("\nSaved metrics to:", csv_filepath, "\n")

# Stop capturing output
#sink()

# Confirm message
#cat("\nAll console outputs saved to:", log_filepath, "\n")
```

```{r}
#save_plot <- function(plot, filename, output_dir = "C:/Users/User/Downloads/SpatioTemporal GPR/All_Plots/") {
#  dir.create(output_dir, showWarnings = FALSE)  # Create directory if it doesn't exist
#  filepath <- file.path(output_dir, paste0(filename, ".png"))
#  ggsave(filepath, plot = plot, width = 8, height = 6, dpi = 300)
#  cat("Saved:", filepath, "\n")  # Print message
#}
```

### Plot

#### Predicted Vs. Actual

```{r}

# Iterate over each kernel and create individual plots
for (kern in selected_kernels) {
  # Get predictions for the kernel
  preds <- predict(models[[kern]], as.matrix(test_data[, c("Date", "X", "Y")]))
  
  # Create a data frame for plotting
  plot_df <- data.frame(Actual = test_data$Value, Predicted = preds)

  p <- ggplot(plot_df, aes(x = Actual, y = Predicted)) +
    geom_point(color = "blue", alpha = 0.6) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
    theme_minimal() +
    labs(title = paste("Actual vs. Predicted -", kern),
         x = "Actual Values (y)",
         y = "Predicted Values (ŷ)") +
    theme(plot.title = element_text(hjust = 0.5))

  print(p)
  #save_plot(p, paste0("Actual_vs_Predicted_", kern))
}

```

#### Spatial Plot

```{r}
# Load Hungary shapefile (already processed)
hungary_sf <- st_read("C:/Users/User/Downloads/hungary_shp/hu.shp") %>%
  rename(Region = name) %>%
  mutate(Region = toupper(Region))

# Define city-to-county mapping 
city_to_county <- c(
  "SOPRON" = "GYOR-MOSON-SOPRON",
  "SZEGED" = "CSONGRÁD",
  "SALGÓTARJÁN" = "NÓGRÁD",
  "SZOLNOK" = "JÁSZ-NAGYKUN-SZOLNOK",
  "ÉRD" = "PEST",
  "EGER" = "HEVES",
  "MISKOLC" = "BORSOD-ABAÚJ-ZEMPLÉN",
  "HÓDMEZÔVÁSÁRHELY" = "CSONGRÁD",
  "DUNAÚJVÁROS" = "FEJÉR",
  "KECSKEMÉT" = "BÁCS-KISKUN",
  "TATABÁNYA" = "KOMÁROM-ESZTERGOM",
  "GYÔR" = "GYOR-MOSON-SOPRON",
  "SZOMBATHELY" = "VAS",
  "ZALAEGERSZEG" = "ZALA",
  "NAGYKANIZSA" = "ZALA",
  "KAPOSVÁR" = "SOMOGY",
  "PÉCS" = "BARANYA",
  "SZEKSZÁRD" = "TOLNA",
  "SZÉKESFEHÉRVÁR" = "FEJÉR",
  "BÉKÉSCSABA" = "BÉKÉS",
  "DEBRECEN" = "HAJDÚ-BIHAR",
  "NYÍREGYHÁZA" = "SZABOLCS-SZATMÁR-BEREG"
)


# Merge city-to-county mappings 
hungary_sf$Region <- recode(hungary_sf$Region, !!!city_to_county)

# counties are merged properly
hungary_sf <- hungary_sf %>%
  group_by(Region) %>%
  summarise(geometry = st_union(geometry), .groups = "drop")

# Define the prediction week (next week)
future_week_numeric <- max(test_data$Date)  # Last test date in numeric format
future_week_actual <- as.Date(future_week_numeric, origin = "2010-01-04")  # Convert back to actual date

# Iterate over kernels to generate spatial maps
for (kern in selected_kernels) {
  # Extract predicted values for next week
  future_data <- test_data[test_data$Date == future_week_numeric, ]
  future_preds <- predict(models[[kern]], as.matrix(future_data[, c("Date", "X", "Y")]))
  
  # Create prediction dataframe
  prediction_df <- data.frame(
    Region = future_data$Region,
    Prediction = future_preds
  )

  # Merge predictions with Hungary shapefile
  hungary_pred_sf <- hungary_sf %>%
    left_join(prediction_df, by = "Region")


  p <- ggplot() +
    geom_sf(data = hungary_pred_sf, aes(fill = Prediction), color = "black") +  # Region color = prediction
    scale_fill_viridis_c(option = "plasma", direction = -1) +  # Use Viridis color scheme
    theme_minimal() +
    labs(title = paste("Predicted Chickenpox Cases for", format(future_week_actual, "%Y-%m-%d"), "-", kern),
         fill = "Predicted Cases") +
    theme(plot.title = element_text(hjust = 0.5))

  print(p)
  #save_plot(p, paste0("Predicted Chickenpox Cases for", 
  #                    format(future_week_actual, "%Y-%m-%d"), "-", kern))
}

```

```{r}

# Get last date from the dataset 
last_date_numeric <- max(test_data$Date)
last_date_actual <- as.Date(last_date_numeric, origin = "2014-12-29")  # Convert to actual date

# Generate next 4 weekly dates 
future_weeks_numeric <- last_date_numeric + c(7, 14, 21, 28, 35, 42, 49, 56, 63)  # Next four weeks
future_weeks_actual <- as.Date(future_weeks_numeric, origin = "2010-01-04")  # Convert to actual dates

# Iterate over kernels and future weeks
for (kern in selected_kernels) {
  for (i in seq_along(future_weeks_numeric)) {
    future_week_numeric <- future_weeks_numeric[i]
    future_week_actual <- future_weeks_actual[i]

    # Create a new test set for this week (using existing locations)
    future_data <- test_data[test_data$Date == last_date_numeric, ]  # Copy last available data
    future_data$Date <- future_week_numeric  # Assign new prediction week

    # Predict using the trained model
    future_preds <- predict(models[[kern]], as.matrix(future_data[, c("Date", "X", "Y")]))

    # Create prediction dataframe
    prediction_df <- data.frame(
      Region = future_data$Region,
      Prediction = future_preds
    )

    # Merge predictions with Hungary shapefile
    hungary_pred_sf <- hungary_sf %>%
      left_join(prediction_df, by = "Region")


    p <- ggplot() +
      geom_sf(data = hungary_pred_sf, aes(fill = Prediction), color = "black") +  
      scale_fill_viridis_c(option = "plasma", direction = -1) +  
      theme_minimal() +
      labs(title = paste("Predicted Chickenpox Cases for", format(future_week_actual, "%Y-%m-%d"), "-", kern),
           fill = "Predicted Cases") +
      theme(plot.title = element_text(hjust = 0.5))

    print(p)
    #save_plot(p, paste0("Predicted Chickenpox Cases for", 
    #                    format(future_week_actual, "%Y-%m-%d"), "-", kern))
  }
}

```
